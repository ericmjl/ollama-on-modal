name: Test Deployment and GPU Routing

on:
  push:
    branches: [main, develop]
  pull_request:
    types: [opened, synchronize, reopened]

jobs:
  deploy:
    name: Deploy to Modal Test Environment
    runs-on: ubuntu-latest
    timeout-minutes: 30

    env:
      MODAL_TOKEN_ID: ${{ secrets.MODAL_TOKEN_ID }}
      MODAL_TOKEN_SECRET: ${{ secrets.MODAL_TOKEN_SECRET }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install pixi
        uses: prefix-dev/setup-pixi@v0.9.3

      - name: Install dependencies
        run: pixi install

      - name: Authenticate with Modal
        run: |
          pixi run modal token set --token-id "$MODAL_TOKEN_ID" --token-secret "$MODAL_TOKEN_SECRET"

      - name: Deploy to Modal (test environment)
        id: deploy
        run: |
          # Deploy to test environment
          # Use --env test to deploy to the test environment (separate from main/production)
          # App name is always "ollama-service" (consistent across environments)
          # TODO: Eventually extract endpoint URL dynamically from deployment output
          pixi run modal deploy endpoint.py --env test

          # Hard-coded endpoint URL for test environment
          # Format: https://{username}-{env-suffix}--{app-name}-{class-name}-{method-name}.modal.run
          # TODO: Extract dynamically from deployment output instead of hard-coding
          ENDPOINT_URL="https://ericmjl-test--ollama-service-ollamaservice-server.modal.run"
          echo "Endpoint URL: $ENDPOINT_URL"
          echo "MODAL_ENDPOINT_URL=$ENDPOINT_URL" >> $GITHUB_ENV
          {
            echo "endpoint_url<<EOF"
            echo "$ENDPOINT_URL"
            echo "EOF"
          } >> $GITHUB_OUTPUT

      - name: Wait for deployment to be ready
        run: |
          if [ -z "$MODAL_ENDPOINT_URL" ]; then
            echo "Error: Could not determine endpoint URL"
            exit 1
          fi

          echo "Waiting for endpoint to be ready: $MODAL_ENDPOINT_URL"
          MAX_ATTEMPTS=30
          ATTEMPT=0

          while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
            if curl -f -s "$MODAL_ENDPOINT_URL/api/version" > /dev/null 2>&1; then
              echo "Endpoint is ready!"
              exit 0
            fi
            ATTEMPT=$((ATTEMPT + 1))
            echo "Attempt $ATTEMPT/$MAX_ATTEMPTS: Waiting for endpoint..."
            sleep 10
          done

          echo "Error: Endpoint did not become ready within timeout"
          exit 1

  test:
    name: Test GPU Routing with LlamaBot
    runs-on: ubuntu-latest
    needs: deploy
    timeout-minutes: 15

    env:
      # Hard-coded endpoint URL for test environment
      # Format: https://{username}-{env-suffix}--{app-name}-{class-name}-{method-name}.modal.run
      # TODO: Extract dynamically from deploy job output instead of hard-coding
      MODAL_ENDPOINT_URL: "https://ericmjl-test--ollama-service-ollamaservice-server.modal.run"
      H100_TEST_MODEL: ${{ vars.H100_TEST_MODEL || 'deepseek-r1:32b' }}
      A10G_TEST_MODEL: ${{ vars.A10G_TEST_MODEL || 'llama3.2' }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Run GPU routing tests
        run: |
          if [ -z "$MODAL_ENDPOINT_URL" ]; then
            echo "Error: MODAL_ENDPOINT_URL not set"
            exit 1
          fi

          uv run scripts/test_gpu_routing.py

      - name: Upload test results
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: |
            tests/*.log
            tests/*.txt

